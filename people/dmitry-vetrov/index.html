<!DOCTYPE html>
<html lang="en">
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127803291-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127803291-1');
</script>

        
        <title>Dmitry Vetrov – Bayesian Methods Research Group</title>
        <meta property="twitter:site" content="@bayesgroup" />
        <meta property="twitter:card" content="summary" />
        <meta property="og:title" content="Dmitry Vetrov – Bayesian Methods Research Group" />
        <meta property="og:description" content="Dmitry Vetrov (graduated from Moscow State Univerisity in 2003, PhD in 2006) is a research professor at Higher School of Economics, Moscow, and head of machine learning lab at Samsung AI Center in Moscow. He is a founder and the head of the Bayesian..." />
        <meta property="og:image" content="http://bayesgroup.ru/photos/vetrov.jpg" />
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <!--[if lte IE 8]><script src="/theme/js/ie/html5shiv.js"></script><![endif]-->
        <link rel="stylesheet" href="/theme/css/main.css" />
        <!--[if lte IE 8]><link rel="stylesheet" href="/theme/css/ie8.css" /><![endif]-->
</head>

<body>
        <!-- Header -->
            <section id="header">
                <header>
                    <span class="image"><a href="/"><img src="/theme/images/bayesgroup.png" alt="" /></a></span>
                    <h1 id="logo">Bayesian Methods Research Group</h1>
                    <p>from Moscow, Russia <!-- with love :-) --></p>
                </header>
                <nav id="nav">
                    <ul>
                                    <li><a href="/about/">About</a></li>
                                    <li class="active"><a href="/people">People</a></li>
                                    <li><a href="/publications">Publications</a></li>
                                    <li><a href="/teaching">Teaching</a></li>
                                    <li><a href="/admission/">Admission</a></li>
                                    <li><a href="/alumni/">Alumni</a></li>
                    </ul>
                </nav>
                <footer>
                    <ul class="icons">
                        <li><a href="https://twitter.com/bayesgroup" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
                        <li><a href="https://www.youtube.com/channel/UC9KcwaZ9gSvcYNs7Jx3oNaQ" class="icon fa-youtube"><span class="label">Youtube</span></a></li>
                        <li><a href="mailto:info@bayesgroup.ru" class="icon fa-envelope"><span class="label">Email</span></a></li>
                    </ul>
                </footer>
            </section>

        <!-- Wrapper -->
            <div id="wrapper">

                <!-- Group Photo -->
                    <section id="photo">
                        <div class="container">
                            <span class="image fit"><img src="/theme/images/banner.jpg" alt="" /></span>
                         </div>
                    </section>

                <!-- Main -->
                    <div id="main">
<section id="page">
	<div class="container">
		<header class="major">
			<h2>Dmitry Vetrov</h2>
		</header>

    <p><img src="/photos/vetrov.jpg" width="200" align="left" class="image avatar" style="margin-right: 1em" />
Dmitry Vetrov (graduated from Moscow State Univerisity in 2003, PhD in 2006) is a research professor at Higher School of Economics, Moscow, and head of machine learning lab at Samsung AI Center in Moscow. He is a founder and the head of the Bayesian Methods Research Group which became one of the strongest research groups in Russia. Three of his recent PhD students became researchers at DeepMind. His research focuses on combining Bayesian framework with Deep Learning models. His group
is also actively involved in building scalable tools for stochastic optimization, application of tensor decomposition methods to large-scale Machine Learning, constructing cooperative multi-agent systems, etc.</p>
<p><a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Google Scholar</a></p>

    <h4>Recent Publications</h4>
    <ul>
            <li>
                <a href="/publications/2019-low-variance-black-box-gradient-estimates-for-the-plackett-luce-distribution/">
                Low-variance Black-box Gradient Estimates for the Plackett-Luce Distribution (2019)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n940">
                Structured Sparsification of Gated Recurrent Neural Networks (2019)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n930">
                Unsupervised Domain Adaptation with Shared Latent Dynamics for Reinforcement Learning (2019)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n920">
                Low-variance Gradient Estimates for the Plackett-Luce Distribution (2019)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n910">
                Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-a-prior-of-a-googol-gaussians:-a-tensor-ring-induced-prior-for-generative-models/">
                A Prior of a Googol Gaussians: a Tensor Ring Induced Prior for Generative Models (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-a-simple-baseline-for-bayesian-uncertainty-in-deep-learning/">
                A Simple Baseline for Bayesian Uncertainty in Deep Learning (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-the-implicit-metropolis-hastings-algorithm/">
                The Implicit Metropolis-Hastings Algorithm (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-importance-weighted-hierarchical-variational-inference/">
                Importance Weighted Hierarchical Variational Inference (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-subspace-inference-for-bayesian-deep-learning/">
                Subspace Inference for Bayesian Deep Learning (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-semi-conditional-normalizing-flows-for-semi-supervised-learning/">
                Semi-Conditional Normalizing Flows for Semi-Supervised Learning (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-variational-autoencoder-with-arbitrary-conditioning/">
                Variational Autoencoder with Arbitrary Conditioning (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-variance-networks-when-expectation-does-not-meet-your-expectations/">
                Variance Networks: When Expectation Does Not Meet Your Expectations (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-the-deep-weight-prior/">
                The Deep Weight Prior (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-doubly-semi-implicit-variational-inference/">
                Doubly Semi-Implicit Variational Inference (2019)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n775">
                Probabilistic Adaptive Computation Time (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n770">
                Bayesian Sparsification of Gated Recurrent Neural Networks (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n760">
                Joint Belief Tracking and Reward Optimization through Approximate Inference (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n750">
                Importance Weighted Hierarchical Variational Inference (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n740">
                Variational Dropout via Empirical Bayes (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n730">
                Subset-Conditioned Generation Using Variational Autoencoder With A Learnable Tensor-Train Induced Prior (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n720">
                Entangled Conditional Adversarial Autoencoder for de Novo Drug Discovery (2018)
                </a>
            </li>
            <li>
                <a href="/publications/2018-loss-surfaces-mode-connectivity-and-fast-ensembling-of-dnns/">
                Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n690">
                Bayesian Compression for Natural Language Processing (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n685">
                Fast Uncertainty Estimates and Bayesian Model Averaging of DNNs (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n680">
                Improving Stability in Deep Reinforcement Learning with Weight Averaging (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n670">
                Averaging Weights Leads to Wider Optima and Better Generalization (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n660">
                Conditional Generators of Words Definitions (2018)
                </a>
            </li>
            <li>
                <a href="/publications/2018-reset-learning-recurrent-dynamic-routing-in-resnet-like-neural-networks/">
                ReSet: Learning Recurrent Dynamic Routing in ResNet-like Neural Networks (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n610">
                Predictive model for bottomhole pressure based on machine learning (2018)
                </a>
            </li>
            <li>
                <a href="/publications/2018-uncertainty-estimation-via-stochastic-batch-normalization/">
                Uncertainty Estimation via Stochastic Batch Normalization (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n590">
                Bayesian Incremental Learning for Deep Neural Networks (2018)
                </a>
            </li>
            <li>
                <a href="/publications/2017-structured-bayesian-pruning-via-log-normal-multiplicative-noise/">
                Structured Bayesian Pruning via Log-Normal Multiplicative Noise (2017)
                </a>
            </li>
            <li>
                <a href="/publications/2017-spatially-adaptive-computation-time-for-residual-networks/">
                Spatially Adaptive Computation Time for Residual Networks (2017)
                </a>
            </li>
            <li>
                <a href="/publications/2017-variational-dropout-sparsifies-deep-neural-networks/">
                Variational Dropout Sparsifies Deep Neural Networks (2017)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n540">
                Bayesian Sparsification of Recurrent Neural Networks (2017)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n470">
                Breaking Sticks and Ambiguities with Adaptive Skip-gram (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n460">
                Deep Part-Based Generative Shape Model with Latent Variables (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n450">
                A New Approach for Sparse Bayesian Channel Estimation in SCMA Uplink Systems (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n430">
                PerforatedCNNs: Acceleration through Elimination of Redundant Convolutions (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n420">
                Dropout-based Automatic Relevance Determination (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n410">
                Robust Variational Inference (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n400">
                Ultimate tensorization: convolutions and FC alike (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n360">
                Tensorizing Neural Networks (2015)
                </a>
            </li>
    </ul>
    </div>
</section>
                    </div>

                <!-- Footer -->
                    <section id="footer">
                        <div class="container">
                            <ul class="copyright">
                                <li>Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
                            </ul>
                        </div>
                    </section>

            </div>

        <!-- Scripts -->
            <script src="/theme/js/jquery.min.js"></script>
            <script src="/theme/js/jquery.scrollzer.min.js"></script>
            <script src="/theme/js/jquery.scrolly.min.js"></script>
            <script src="/theme/js/skel.min.js"></script>
            <script src="/theme/js/util.js"></script>
            <!--[if lte IE 8]><script src="theme/js/ie/respond.min.js"></script><![endif]-->
            <script src="/theme/js/main.js"></script>

</body>
</html>