<!DOCTYPE html>
<html lang="en">
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127803291-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127803291-1');
</script>

        
        <title>Dmitry Vetrov – Bayesian Methods Research Group</title>
        <meta property="twitter:site" content="@bayesgroup" />
        <meta property="twitter:card" content="summary" />
        <meta property="og:title" content="Dmitry Vetrov – Bayesian Methods Research Group" />
        <meta property="og:description" content="I am the head of Bayesian Methods research group. I graduated from Moscow State University (MSU) in 2003 and obtained PhD degree at the department of Computational Mathematics and Cybernetics of MSU in 2006. Currently I am an associate professor at..." />
        <meta property="og:image" content="http://bayesgroup.ru/photos/vetrov.jpg" />
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <!--[if lte IE 8]><script src="/theme/js/ie/html5shiv.js"></script><![endif]-->
        <link rel="stylesheet" href="/theme/css/main.css" />
        <!--[if lte IE 8]><link rel="stylesheet" href="/theme/css/ie8.css" /><![endif]-->
</head>

<body>
        <!-- Header -->
            <section id="header">
                <header>
                    <span class="image"><a href="/"><img src="/theme/images/bayesgroup.png" alt="" /></a></span>
                    <h1 id="logo">Bayesian Methods Research Group</h1>
                    <p>from Moscow, Russia <!-- with love :-) --></p>
                </header>
                <nav id="nav">
                    <ul>
                                    <li><a href="/about/">About</a></li>
                                    <li class="active"><a href="/people">People</a></li>
                                    <li><a href="/publications">Publications</a></li>
                                    <li><a href="/teaching">Teaching</a></li>
                                    <li><a href="/admission/">Admission</a></li>
                                    <li><a href="/alumni/">Alumni</a></li>
                    </ul>
                </nav>
                <footer>
                    <ul class="icons">
                        <li><a href="https://twitter.com/bayesgroup" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
                        <li><a href="https://www.youtube.com/channel/UC9KcwaZ9gSvcYNs7Jx3oNaQ" class="icon fa-youtube"><span class="label">Youtube</span></a></li>
                        <li><a href="mailto:info@bayesgroup.ru" class="icon fa-envelope"><span class="label">Email</span></a></li>
                    </ul>
                </footer>
            </section>

        <!-- Wrapper -->
            <div id="wrapper">

                <!-- Group Photo -->
                    <section id="photo">
                        <div class="container">
                            <span class="image fit"><img src="/theme/images/banner.jpg" alt="" /></span>
                         </div>
                    </section>

                <!-- Main -->
                    <div id="main">
<section id="page">
	<div class="container">
		<header class="major">
			<h2>Dmitry Vetrov</h2>
		</header>

    <p><img src="/photos/vetrov.jpg" width="150" align="left" class="image avatar" style="margin-right: 1em" />
I am the head of Bayesian Methods research group. I graduated from Moscow State University (MSU) in 2003 and obtained PhD degree at the department of Computational Mathematics and Cybernetics of MSU in 2006. Currently I am an associate professor at <a href="http://cs.hse.ru/en">Higher School of Economics</a>. I also read lectures at <a href="https://yandexdataschool.com/">Yandex  School of Data Analysis</a> and at  <a href="https://cs.msu.ru/en">Moscow State University</a>.</p>
<p>I believe that we’re moving towards The New Mathematics or the mathematics of big data age where compeletely new learning, inference, optimization and storage technologies will appear. The first steps (Deep Learning, Tensor Decomposition, Stochastic Optimization) have been already made but many more are to come. Creation of such new technologies is our mission.</p>
<p>My hobby is World History, Geopolitics, and World War II. You may find some of my public lectures on various historical events on youtube (in Russian).</p>
<p>One of the things I love in my job is having PhD students who are smarter than me :)</p>
<p>My research interests include (but not limited to):</p>
<ul>
<li>Machine Learning</li>
<li>Deep Neural Networks</li>
<li>Probabilistic Graphical Models</li>
<li>Computer Vision</li>
<li>Text Processing</li>
<li>Error-correcting codes</li>
</ul>
<p><a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Google Scholar</a></p>

    <h4>Recent Publications</h4>
    <ul>
            <li>
                <a href="/publications/2019-variational-autoencoder-with-arbitrary-conditioning/">
                Variational Autoencoder with Arbitrary Conditioning (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-variance-networks-when-expectation-does-not-meet-your-expectations/">
                Variance Networks: When Expectation Does Not Meet Your Expectations (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-the-deep-weight-prior/">
                The Deep Weight Prior (2019)
                </a>
            </li>
            <li>
                <a href="/publications/2019-doubly-semi-implicit-variational-inference/">
                Doubly Semi-Implicit Variational Inference (2019)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n775">
                Probabilistic Adaptive Computation Time (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n720">
                Entangled Conditional Adversarial Autoencoder for de Novo Drug Discovery (2018)
                </a>
            </li>
            <li>
                <a href="/publications/2018-loss-surfaces-mode-connectivity-and-fast-ensembling-of-dnns/">
                Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n690">
                Bayesian Compression for Natural Language Processing (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n685">
                Fast Uncertainty Estimates and Bayesian Model Averaging of DNNs (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n680">
                Improving Stability in Deep Reinforcement Learning with Weight Averaging (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n670">
                Averaging Weights Leads to Wider Optima and Better Generalization (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n660">
                Conditional Generators of Words Definitions (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n610">
                Predictive model for bottomhole pressure based on machine learning (2018)
                </a>
            </li>
            <li>
                <a href="/publications/2018-uncertainty-estimation-via-stochastic-batch-normalization/">
                Uncertainty Estimation via Stochastic Batch Normalization (2018)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n590">
                Bayesian Incremental Learning for Deep Neural Networks (2018)
                </a>
            </li>
            <li>
                <a href="/publications/2017-structured-bayesian-pruning-via-log-normal-multiplicative-noise/">
                Structured Bayesian Pruning via Log-Normal Multiplicative Noise (2017)
                </a>
            </li>
            <li>
                <a href="/publications/2017-spatially-adaptive-computation-time-for-residual-networks/">
                Spatially Adaptive Computation Time for Residual Networks (2017)
                </a>
            </li>
            <li>
                <a href="/publications/2017-variational-dropout-sparsifies-deep-neural-networks/">
                Variational Dropout Sparsifies Deep Neural Networks (2017)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n540">
                Bayesian Sparsification of Recurrent Neural Networks (2017)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n470">
                Breaking Sticks and Ambiguities with Adaptive Skip-gram (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n460">
                Deep Part-Based Generative Shape Model with Latent Variables (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n450">
                A New Approach for Sparse Bayesian Channel Estimation in SCMA Uplink Systems (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n430">
                PerforatedCNNs: Acceleration through Elimination of Redundant Convolutions (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n410">
                Robust Variational Inference (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n400">
                Ultimate tensorization: convolutions and FC alike (2016)
                </a>
            </li>
            <li>
                <a href="/publications/#pub-n360">
                Tensorizing Neural Networks (2015)
                </a>
            </li>
    </ul>
    </div>
</section>
                    </div>

                <!-- Footer -->
                    <section id="footer">
                        <div class="container">
                            <ul class="copyright">
                                <li>Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
                            </ul>
                        </div>
                    </section>

            </div>

        <!-- Scripts -->
            <script src="/theme/js/jquery.min.js"></script>
            <script src="/theme/js/jquery.scrollzer.min.js"></script>
            <script src="/theme/js/jquery.scrolly.min.js"></script>
            <script src="/theme/js/skel.min.js"></script>
            <script src="/theme/js/util.js"></script>
            <!--[if lte IE 8]><script src="theme/js/ie/respond.min.js"></script><![endif]-->
            <script src="/theme/js/main.js"></script>

</body>
</html>