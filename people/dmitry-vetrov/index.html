<!DOCTYPE html>
<html lang="en">
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127803291-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127803291-1');
</script>

        
        <title>Dmitry Vetrov – Bayesian Methods Research Group</title>
        <meta property="twitter:site" content="@bayesgroup" />
        <meta property="twitter:card" content="summary" />
        <meta property="og:title" content="Dmitry Vetrov – Bayesian Methods Research Group" />
        <meta property="og:description" content="Dmitry Vetrov (graduated from Moscow State Univerisity in 2003, PhD in 2006) is a professor of Computer Science at Constructor University, Bremen, and a research professor at Higher School of Economics, Moscow. He is a founder and the head of the..." />
        <meta property="og:image" content="http://bayesgroup.ru/photos/vetrov.jpg" />
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <!--[if lte IE 8]><script src="/theme/js/ie/html5shiv.js"></script><![endif]-->
        <link rel="stylesheet" href="/theme/css/main.css" />
        <!--[if lte IE 8]><link rel="stylesheet" href="/theme/css/ie8.css" /><![endif]-->
</head>

<body>
        <!-- Header -->
            <section id="header">
                <header>
                    <span class="image"><a href="/"><img src="/theme/images/bayesgroup.png" alt="" /></a></span>
                    <h1 id="logo">Bayesian Methods Research Group</h1>
                    <p>from Bremen, Germany <br/>and Moscow, Russia <!-- with love :-) --></p>
                </header>
                <nav id="nav">
                    <ul>
                                <li><a href="/about/">About</a></li>
                                <li class="active"><a href="/people">People</a></li>
                                <li><a href="/publications">Publications</a></li>
                                <li><a href="/teaching">Teaching</a></li>
                                <li><a href="/admission/">Admission</a></li>
                                <li><a href="/alumni/">Alumni</a></li>
                    </ul>
                </nav>
                <footer>
                    <ul class="icons">
                        <li><a href="https://twitter.com/bayesgroup" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
                        <li><a href="https://www.youtube.com/@bayesgroup" class="icon fa-youtube"><span class="label">Youtube</span></a></li>
                        <li><a href="mailto:info@bayesgroup.ru" class="icon fa-envelope"><span class="label">Email</span></a></li>
                    </ul>
                </footer>
            </section>

        <!-- Wrapper -->
            <div id="wrapper">

                <!-- Group Photo -->
                    <section id="photo">
                        <div class="container">
                            <span class="image fit"><img src="/theme/images/banner.jpg" alt="" /></span>
                         </div>
                    </section>

                <!-- Main -->
                    <div id="main">
<section id="page">
	<div class="container">
		<header class="major">
			<h2>Dmitry Vetrov</h2>
		</header>

    <p><img src="/photos/vetrov.jpg" width="200" align="left" class="image avatar" style="margin-right: 1em" />
Dmitry Vetrov (graduated from Moscow State Univerisity in 2003, PhD in 2006) is a professor of Computer Science at Constructor University, Bremen, and a research professor at Higher School of Economics, Moscow. He is a founder and the head of the Bayesian Methods Research Group which became one of the strongest research groups in Russia. Three of his recent PhD students became researchers at DeepMind. His research focuses on combining Bayesian framework with Deep Learning models. His group is also actively involved in developing more efficient algorithms for diffusion models, studying the properties of loss landscape in deep neural networks, building scalable tools for stochastic optimization, application of tensor decomposition methods to large-scale Machine Learning, improving conditional text generation models, etc.</p>
<p><a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Google Scholar</a></p>

    <h4>Recent Publications</h4>
    <ul id="recent-publications-list">
            <li>
                <b><a href="/publications/2024-neural-diffusion-models/">Neural Diffusion Models</a></b>
                (2024)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Forty-first International Conference on Machine Learning">ICML 2024</span></span>            </li>
            <li>
                <b><a href="/publications/2024-gradual-optimization-learning-for-conformational-energy-minimization/">Gradual Optimization Learning for Conformational Energy Minimization</a></b>
                (2024)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="The Twelfth International Conference on Learning Representations">ICLR 2024</span></span>            </li>
            <li>
                <b><a href="/publications/2024-the-devil-is-in-the-details-stylefeatureeditor-for-detail-rich-stylegan-inversion-and-high-quality-image-editing/">The Devil is in the Details: StyleFeatureEditor for Detail-Rich StyleGAN Inversion and High Quality Image Editing</a></b>
                (2024)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2024">CVPR 2024</span></span>            </li>
            <li>
                <b><a href="/publications/2024-differentiable-rendering-with-reparameterized-volume-sampling/">Differentiable Rendering with Reparameterized Volume Sampling</a></b>
                (2024)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Twenty-seventh International Conference on Artificial Intelligence and Statistics">AISTATS 2024</span></span>            </li>
            <li>
                <b><a href="/publications/2024-generative-flow-networks-as-entropy-regularized-rl/">Generative Flow Networks as Entropy-Regularized RL</a></b>
                (2024)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Twenty-seventh International Conference on Artificial Intelligence and Statistics">AISTATS 2024</span></span>            </li>
            <li>
                <b><a href="/publications/2023-to-stay-or-not-to-stay-in-the-pre-train-basin-insights-on-ensembling-in-transfer-learning/">To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning</a></b>
                (2023)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Thirty-seventh Conference on Neural Information Processing Systems">NeurIPS 2023</span></span>            </li>
            <li>
                <b><a href="/publications/2023-star-shaped-denoising-diffusion-probabilistic-models/">Star-Shaped Denoising Diffusion Probabilistic Models</a></b>
                (2023)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Thirty-seventh Conference on Neural Information Processing Systems">NeurIPS 2023</span></span>            </li>
            <li>
                <b><a href="/publications/2023-entropic-neural-optimal-transport-via-diffusion-processes/">Entropic Neural Optimal Transport via Diffusion Processes</a></b>
                (2023)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Thirty-seventh Conference on Neural Information Processing Systems">NeurIPS 2023</span></span>            </li>
            <li>
                <b><a href="/publications/2023-styledomain-efficient-and-lightweight-parameterizations-of-stylegan-for-one-shot-and-few-shot-domain-adaptation-model/">StyleDomain: Efficient and Lightweight Parameterizations of StyleGAN for One-shot and Few-shot Domain Adaptation</a></b>
                (2023)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="International Conference on Computer Vision">ICCV 2023</span></span>            </li>
            <li>
                <b><a href="/publications/2023-undiff-unsupervised-voice-restoration-with-unconditional-diffusion-model/">UnDiff: Unsupervised Voice Restoration with Unconditional Diffusion Model</a></b>
                (2023)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="24th INTERSPEECH Conference">Interspeech 2023</span></span>            </li>
            <li>
                <b><a href="/publications/2023-hifipp-a-unified-framework-for-bandwidth-extension-and-speech-enhancement/">HIFI++: A Unified Framework for Bandwidth Extension and Speech Enhancement</a></b>
                (2023)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="2023 IEEE International Conference on Acoustics, Speech and Signal Processing">ICASSP 2023</span></span>            </li>
            <li>
                <b><a href="/publications/2023-mars-masked-automatic-ranks-selection-in-tensor-decompositions/">MARS: Masked Automatic Ranks Selection in Tensor Decompositions</a></b>
                (2023)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="The 26th International Conference on Artificial Intelligence and Statistics">AISTATS 2023</span></span>            </li>
            <li>
                <b><a href="/publications/2022-hyperdomainnet-universal-domain-adaptation-for-generative-adversarial-networks/">HyperDomainNet: Universal Domain Adaptation for Generative Adversarial Network</a></b>
                (2022)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Thirty-sixth Conference on Neural Information Processing Systems">NeurIPS 2022</span></span>            </li>
            <li>
                <b><a href="/publications/2022-training-scale-invariant-neural-networks-on-the-sphere-can-happen-in-three-regimes/">Training Scale-Invariant Neural Networks on the Sphere Can Happen in Three Regimes</a></b>
                (2022)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Thirty-sixth Conference on Neural Information Processing Systems">NeurIPS 2022</span></span>            </li>
            <li>
                <b><a href="/publications/2022-ffc-se-fast-fourier-convolution-for-speech-enhancement/">FFC-SE: Fast Fourier Convolution for Speech Enhancement</a></b>
                (2022)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="23rd INTERSPEECH Conference">INTERSPEECH 2022</span></span>            </li>
    </ul>
    </div>
</section>
                    </div>

                <!-- Footer -->
                    <section id="footer">
                        <div class="container">
                            <ul class="copyright">
                                <li>Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
                            </ul>
                        </div>
                    </section>

            </div>

        <!-- Scripts -->
            <script src="/theme/js/jquery.min.js"></script>
            <script src="/theme/js/jquery.scrollzer.min.js"></script>
            <script src="/theme/js/jquery.scrolly.min.js"></script>
            <script src="/theme/js/skel.min.js"></script>
            <script src="/theme/js/util.js"></script>
            <!--[if lte IE 8]><script src="theme/js/ie/respond.min.js"></script><![endif]-->
            <script src="/theme/js/main.js"></script>

</body>
</html>