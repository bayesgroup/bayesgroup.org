<!DOCTYPE html>
<html lang="en">
<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127803291-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127803291-1');
</script>

        
        <title>Dmitry Vetrov – Bayesian Methods Research Group</title>
        <meta property="twitter:site" content="@bayesgroup" />
        <meta property="twitter:card" content="summary" />
        <meta property="og:title" content="Dmitry Vetrov – Bayesian Methods Research Group" />
        <meta property="og:description" content="Dmitry Vetrov (graduated from Moscow State Univerisity in 2003, PhD in 2006) is a research professor at Higher School of Economics, Moscow, and leading researcher at AIRI, Moscow. He is a founder and the head of the Bayesian Methods Research Group..." />
        <meta property="og:image" content="http://bayesgroup.ru/photos/vetrov.jpg" />
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <!--[if lte IE 8]><script src="/theme/js/ie/html5shiv.js"></script><![endif]-->
        <link rel="stylesheet" href="/theme/css/main.css" />
        <!--[if lte IE 8]><link rel="stylesheet" href="/theme/css/ie8.css" /><![endif]-->
</head>

<body>
        <!-- Header -->
            <section id="header">
                <header>
                    <span class="image"><a href="/"><img src="/theme/images/bayesgroup.png" alt="" /></a></span>
                    <h1 id="logo">Bayesian Methods Research Group</h1>
                    <p>from Moscow, Russia <!-- with love :-) --></p>
                </header>
                <nav id="nav">
                    <ul>
                                <li><a href="/about/">About</a></li>
                                <li class="active"><a href="/people">People</a></li>
                                <li><a href="/publications">Publications</a></li>
                                <li><a href="/teaching">Teaching</a></li>
                                <li><a href="/admission/">Admission</a></li>
                                <li><a href="/alumni/">Alumni</a></li>
                    </ul>
                </nav>
                <footer>
                    <ul class="icons">
                        <li><a href="https://twitter.com/bayesgroup" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
                        <li><a href="https://www.youtube.com/channel/UC9KcwaZ9gSvcYNs7Jx3oNaQ" class="icon fa-youtube"><span class="label">Youtube</span></a></li>
                        <li><a href="mailto:info@bayesgroup.ru" class="icon fa-envelope"><span class="label">Email</span></a></li>
                    </ul>
                </footer>
            </section>

        <!-- Wrapper -->
            <div id="wrapper">

                <!-- Group Photo -->
                    <section id="photo">
                        <div class="container">
                            <span class="image fit"><img src="/theme/images/banner.jpg" alt="" /></span>
                         </div>
                    </section>

                <!-- Main -->
                    <div id="main">
<section id="page">
	<div class="container">
		<header class="major">
			<h2>Dmitry Vetrov</h2>
		</header>

    <p><img src="/photos/vetrov.jpg" width="200" align="left" class="image avatar" style="margin-right: 1em" />
Dmitry Vetrov (graduated from Moscow State Univerisity in 2003, PhD in 2006) is a research professor at Higher School of Economics, Moscow, and leading researcher at AIRI, Moscow. He is a founder and the head of the Bayesian Methods Research Group which became one of the strongest research groups in Russia. Three of his recent PhD students became researchers at DeepMind. His research focuses on combining Bayesian framework with Deep Learning models. His group is also actively involved in developing more efficient algorithms for diffusion models, studying the properties of loss landscape in deep neural networks, building scalable tools for stochastic optimization, application of tensor decomposition methods to large-scale Machine Learning, improving conditional text generation models, etc.</p>
<p><a href="https://scholar.google.com/citations?user=7HU0UoUAAAAJ&hl=en">Google Scholar</a></p>

    <h4>Recent Publications</h4>
    <ul id="recent-publications-list">
            <li>
                <b><a href="/publications/2023-styledomain-efficient-and-lightweight-parameterizations-of-stylegan-for-one-shot-and-few-shot-domain-adaptation-model/">StyleDomain: Efficient and Lightweight Parameterizations of StyleGAN for One-shot and Few-shot Domain Adaptation</a></b>
                (2023)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="International Conference on Computer Vision">ICCV 2023</span></span>            </li>
            <li>
                <b><a href="/publications/2023-undiff-unsupervised-voice-restoration-with-unconditional-diffusion-model/">UnDiff: Unsupervised Voice Restoration with Unconditional Diffusion Model</a></b>
                (2023)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="24th INTERSPEECH Conference">Interspeech 2023</span></span>            </li>
            <li>
                <b><a href="/publications/2023-mars-masked-automatic-ranks-selection-in-tensor-decompositions/">MARS: Masked Automatic Ranks Selection in Tensor Decompositions</a></b>
                (2023)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="The 26th International Conference on Artificial Intelligence and Statistics">AISTATS 2023</span></span>            </li>
            <li>
                <b><a href="/publications/2022-hyperdomainnet-universal-domain-adaptation-for-generative-adversarial-networks/">HyperDomainNet: Universal Domain Adaptation for Generative Adversarial Network</a></b>
                (2022)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Thirty-sixth Conference on Neural Information Processing Systems">NeurIPS 2022</span></span>            </li>
            <li>
                <b><a href="/publications/2022-training-scale-invariant-neural-networks-on-the-sphere-can-happen-in-three-regimes/">Training Scale-Invariant Neural Networks on the Sphere Can Happen in Three Regimes</a></b>
                (2022)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Thirty-sixth Conference on Neural Information Processing Systems">NeurIPS 2022</span></span>            </li>
            <li>
                <b><a href="/publications/2022-ffc-se-fast-fourier-convolution-for-speech-enhancement/">FFC-SE: Fast Fourier Convolution for Speech Enhancement</a></b>
                (2022)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="23rd INTERSPEECH Conference">INTERSPEECH 2022</span></span>            </li>
            <li>
                <b><a href="/publications/2022-variational-autoencoders-for-precoding-matrices-with-high-spectral-efficiency/">Variational Autoencoders for Precoding Matrices with High Spectral Efficiency</a></b>
                (2022)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="21st International Conference Mathematical Optimization Theory and Operations Research: Recent Trends">MOTOR 2022</span></span>            </li>
            <li>
                <b><a href="/publications/2021-on-the-periodic-behavior-of-neural-network-training-with-batch-normalization-and-weight-decay/">On the Periodic Behavior of Neural Network Training with Batch Normalization and Weight Decay</a></b>
                (2021)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Advances in Neural Information Processing Systems 34">NeurIPS 2021</span></span>            </li>
            <li>
                <b><a href="/publications/2021-leveraging-recursive-gumbel-max-trick-for-approximate-inference-in-combinatorial-spaces/">Leveraging Recursive Gumbel-Max Trick for Approximate Inference in Combinatorial Spaces</a></b>
                (2021)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Thirty-fifth Conference on Neural Information Processing Systems">NeurIPS 2021</span></span>            </li>
            <li>
                <b><a href="/publications/2020-on-power-laws-in-deep-ensembles-full/">On Power Laws in Deep Ensembles</a></b>
                (2020)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Thirty-fourth Conference on Neural Information Processing Systems">NeurIPS 2020</span></span>            </li>
            <li>
                <b><a href="/publications/#pub-n1000">On Power Laws in Deep Ensembles</a></b>
                (2020)
            </li>
            <li>
                <b><a href="/publications/2020-involutive-mcmc-one-way-to-derive-them-all/">Involutive MCMC: One Way to Derive Them All</a></b>
                (2020)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Thirty-seventh International Conference on Machine Learning">ICML 2020</span></span>            </li>
            <li>
                <b><a href="/publications/2020-controlling-overestimation-bias-with-truncated-mixture-of-continuous-distributional-quantile-critics/">Controlling Overestimation Bias with Truncated Mixture of Continuous Distributional Quantile Critics</a></b>
                (2020)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Thirty-seventh International Conference on Machine Learning">ICML 2020</span></span>            </li>
            <li>
                <b><a href="/publications/2020-greedy-policy-search-a-simple-baseline-for-learnable-test-time-augmentation/">Greedy Policy Search: A Simple Baseline for Learnable Test-Time Augmentation</a></b>
                (2020)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="Conference on Uncertainty in Artificial Intelligence">UAI 2020</span></span>            </li>
            <li>
                <b><a href="/publications/2020-deterministic-decoding-for-discrete-data-in-variational-autoencoders/">Deterministic Decoding for Discrete Data in Variational Autoencoders</a></b>
                (2020)
<span class="ribbon-container"><span class="ribbon-right ribbon-teal" title="The 23rd International Conference on Artificial Intelligence and Statistics">AISTATS 2020</span></span>            </li>
    </ul>
    </div>
</section>
                    </div>

                <!-- Footer -->
                    <section id="footer">
                        <div class="container">
                            <ul class="copyright">
                                <li>Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
                            </ul>
                        </div>
                    </section>

            </div>

        <!-- Scripts -->
            <script src="/theme/js/jquery.min.js"></script>
            <script src="/theme/js/jquery.scrollzer.min.js"></script>
            <script src="/theme/js/jquery.scrolly.min.js"></script>
            <script src="/theme/js/skel.min.js"></script>
            <script src="/theme/js/util.js"></script>
            <!--[if lte IE 8]><script src="theme/js/ie/respond.min.js"></script><![endif]-->
            <script src="/theme/js/main.js"></script>

</body>
</html>